{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Agrupamento\n",
    "\n",
    "**Positivo:**\n",
    "\n",
    "### Como o k-means funciona?<a id='agrupamento_01'></a>\n",
    "> k-means é um algoritmo de aprendizado não-supervisionado e é usado para *encontrar observações que sejam próximas* e, com isso, inferir a existência de grupos com atributos mais similares entre seus elementos.\n",
    "> **Passos:**\n",
    "> 1. Para iniciar o algoritmo k-means, é necessário indicar a quantidade de grupos ou *cluters* que são esperados, essa quantidade é indicada pela letra *k* de k-means.\n",
    "> 2. Os centróides, como são chamados os pontos centrais de cada agrupamentos, são dispostos aleatoriamente no espaço n-dimensional formado pelos atributos/fatores das observações.\n",
    "> 3. Em seguida, são calculadas as distâncias entre todos as observações e os *k* centróides. As observações são associadas ao centróide mais próximo.\n",
    "> 4. Por fim, é calculado o ponto médio das observações de cada agrupamento e o centróide é movido para esse novo ponto.\n",
    "> Os passos 3 e 4 são são executados até que não haja mais alteração na localização dos centróides.\n",
    "\n",
    "### Qual o algoritmo sofreria mais com outliers: k-means ou hierárquico?\n",
    "> Acredito que o **k-means** sofra mais com *outliers* devido a natureza da determinação do centro de cada agrupamento que é localizado na distância média de todas as observações e, como a média é um parâmetro sensível a outliers, a determinação do centro do agrupamento no k-means sensível também. Quando comparamos ao agrupamento hierárquico, temos que o cálculo da distância dos elementos ou grupo a um outro grupo pode ser feito usando diferentes localizações como, por exemplo, (1) os elementos mais próximos (single linkage), os elementos mais distantes (complete linkage), as distâncias médias entre os elementos de ca\n",
    "\n",
    "**Negativo:**\n",
    "\n",
    "### Qual a distância é otimizada no k-means, intra-cluster ou inter-cluster?\n",
    "> A distância otimizada (no caso, minimização) no algoritmo k-means é a distância intracluster, ou seja, a otimização do algoritmo é feita através da minimização das distâncias entre os elementos de um mesmo agrupamento. A medida a ser minimizada é chamada de variação intra-cluster (within-cluster variation), indicada abaixo por $W(C_{k})$:\n",
    "> \n",
    "> $$ Min (W(C_{k}) = \\frac{1}{\\lvert C_{k} \\rvert} \\sum_{i, i` \\in C_{k}} \\sum_{j=1}^p (x_{ij}-x_{i´j})^2) $$\n",
    "> \n",
    "> $W(C_{k})$ é uma função de custo chamada **função de distorção**.\n",
    ">\n",
    "> A minimização da **função de distorção** é usada para a definição da quantidade de agrupamentos/clusters (*k*) que deve iniciar o algoritmo.\n",
    ">\n",
    "\n",
    "### Qual é a diferença entre a abordagem single linkage, complete e average linkage?\n",
    "> A diferença entre as ligações (*linkages*) indicadas é a referência utilizada para calcular a distância entre os agrupamentos formados. A tabela abaixo sumariza cada uma:\n",
    "> \n",
    "> | Ligação | Descrição |\n",
    "> | - | - |\n",
    "> | **Single<br>linkage** | A referência são os<br>**pontos mais próximos**<br>de cada grupo. |\n",
    "> | **Complete<br>linkage** | A referência são os<br>**pontos mais distantes**<br>de cada grupo. |\n",
    "> | **Average<br>linkage** | A distância é a média<br>do somatório das distâncias<br>de todos os pontos de um dos<br>grupos em relação a TODOS<br>os elementos do outro grupo.<br> Menos afetado por *outliers*.|\n",
    "\n",
    "### Quais são as vantagens e desvantagens de um algoritmo hierárquico como a single linkage quando comparado com o algoritmo k-means?\n",
    "> Duas das principais desvantagens do k-means em relação ao algoritmo hierárquico:\n",
    "> 1. No kmeans, é necessária a definição da quantidade de centróides logo de ;\n",
    "> 2. A solução é dependente na localização inicial dos centróides que é atribuída de maneira aleatória e isso pode levar a obtenção de soluções qua não são o mínimo global.\n",
    "\n",
    "### Como definir o número de k no k-means?\n",
    "> O número de centróides (*k*) pode ser definido otimizando (minimizando) a distância intragrupos ou intraclusters. E escolhe-se o *k* com baixa distância intragrupos e até o momento que a variação de *k* reduza.\n",
    "\n",
    "### Comparar elbow, silhueta e silhueta simplificada.\n",
    ">\n",
    "\n",
    "### Qual dos hierárquicos sofre menos com outliers?\n",
    "> Dos tipos de ligação abordados em uma pergunta anterior (Single, Complete e Average), a abordagem de ligação média (average linkage) é a menos susceptível a outliers. Pois como a distância entre os grupos formados é calculada pela média das distâncias de cada ponto de um grupo A em relação a todos os pontos de um grupo B, o impacto de uma distância formada por um ponto no grupo A com o outlier em um grupo B é atenuado pelas outras distâncias que formarão a dissimilaridade entre esses grupos.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classificação:\n",
    "\n",
    "**Positivo:**\n",
    "\n",
    "### Como funciona uma árvore de decisão?\n",
    "\n",
    "> O algoritmo da árvore de decisão é formado por uma série de decisões binárias em sequência. Essas decisões separam um conjunto em dois subconjuntos desde que a divisão aumente a pureza dos grupos formados em relação ao grupo original. Supondo-se apenas atrubutos categóricos, o algoritmo da árvore de decisão seria:\n",
    "> - Inicia-se o algoritmo com todas as observações pertencendo a um único conjunto chamado \"nó raiz\", no topo da árvore.\n",
    "> - Testa-se a divisão com cada um dos atributos e vemos qual tem a maior pureza em relação ao target. Como critério de pureza, dois exemplos são Gini e Entropia.\n",
    "> - Repete-se a etapa anterior para cada subconjunto dos atributos até chegarmos a uma quantidade de elementos mínima em cada folha ou não haver mais ganho de pureza na divisão de um nó.\n",
    "\n",
    "### Para que serve a poda na altura da árvore?\n",
    "\n",
    "> A poda (ou *prune*) tem a função de evitar o overfitting das árvores de decisão e regressão. É adicionado um termo que penaliza a função de custo de acordo com a quantidade de folhas; ou seja, quanto maior a quantidade de folhas, maior a penalização.\n",
    "\n",
    "### Explicar a diferença entre acurácia e precisão.\n",
    "\n",
    "> A acurácia \n",
    "\n",
    "### Explique como os métodos de bagging funcionam.\n",
    "\n",
    "**Negativo:**\n",
    "\n",
    "### Qual é a importância de fazer a seleção de variáveis? Dê um exemplo de como fazer.\n",
    "\n",
    "### Por que nem sempre é bom utilizarmos a acurácia?\n",
    "\n",
    "### Quando utilizamos a F1?\n",
    "\n",
    "### Explique como os métodos de boosting funcionam.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regressão\n",
    "\n",
    "**Positivo:**\n",
    "\n",
    "### Como calcular o MSE?\n",
    "> A métrica de avaliação de modelo **erro quadrático médio** ou **mean squared error** (MSE) é a soma de todos as distâncias reais das observações em relação ao valor previsto pelo modelo. A equação abaixo ilustra esse cálculo:\n",
    "\n",
    "$$  $$\n",
    "\n",
    "### Explicar como o ElasticNet funciona.\n",
    "\n",
    "### Explicar a diferença entre regularização L1 e L2?\n",
    "\n",
    "**Negativo:**\n",
    "\n",
    "### Explicar técnicas de validação cruzada.\n",
    "\n",
    "### Como deve ser feito a escolha da função de ativação de uma rede neural?\n",
    "\n",
    "### Explicar como o modelo SVM funciona.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estatística\n",
    "\n",
    "**Positivo:**\n",
    "\n",
    "### Como calcular média, mediana e moda?\n",
    "\n",
    "> **Média:** somatório dos elementos de uma amostra divididos pela quantidade de elementos dessa amostra.\n",
    ">\n",
    "> $$ Média = \\frac{1}{n}\\sum_{i=1}^nx_{i} $$\n",
    ">\n",
    ">---\n",
    ">\n",
    "> **Mediana:** elemento central de uma amostra. Quando os elementos são colocados em ordem crescente ou decrescente, a mediana é o elemento central, no caso de uma quantidade ímpar de amostras e é a média dos dois elementos centrais se a amostra tiver uma quantidade de elementos par.\n",
    "> **Importante:** A mediana é mais robusta que a média quanto a presença de outliers.\n",
    ">\n",
    ">---\n",
    ">\n",
    "> **Moda:** simplesmente o elemento com maior de ocorrência na amostra.\n",
    ">\n",
    ">---\n",
    "\n",
    "**Negativo:**\n",
    "\n",
    "### Qual é a diferença entre a amostragem por conglomerado e a estratificada? Nesse tipo de amostragem, os conglomerados devem ser homogêneos ou heterogêneos?\n",
    "\n",
    "> Na amostragem estratificada, é feita uma divisão em estratos. Sendo que esses estratos agrupam elementos de uma população com uma determinada característica, que deve ser mutualmente exclusiva aos outros estratos.\n",
    "> No caso da amostragem por conglomerado, a divisão de uma população é dada por localizações geográficas. Os elemnetos dentro de um conglomerado, portanto, devem ser heterogêneos para representar a população.\n",
    "\n",
    "\n",
    "### Como calcular o desvio padrão?\n",
    "\n",
    "> O desvio padrão é uma medida de dispersão que mostra quanto os elementos estão distantes da média da amostra. Quanto mais próximo de 0, menos disperso é a amostra.\n",
    "> $$ \\sigma = \\sqrt{\\frac{\\sum_{i=1}^n(x_{i}-\\bar{x})}{n}} $$\n",
    "> Importante que a variâcia é o quadrado do desvio padrão.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQL\n",
    "\n",
    "**Positivo:**\n",
    "\n",
    "### Qual é a diferença entre inner join e left join?\n",
    "\n",
    "### Dê um exemplo de uma situação na qual podemos usar a cláusula *group by*.\n",
    "\n",
    "**Negativo:**\n",
    "\n",
    "### Suponha que precisamos fazer uma junção (JOIN) de duas tabelas muito grandes. Como podemos acelerar o processo?\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
